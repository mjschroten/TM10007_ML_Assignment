{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template -- ECG data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "lK44S6bKvDvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from statistics import median\n",
        "from scipy.stats import normaltest\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve,  average_precision_score, PrecisionRecallDisplay, ConfusionMatrixDisplay, f1_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "hWbJd3An9_NV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_VsRlKukSmc"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CiDn2Sk-VWqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a74413-30a0-4b8f-f0e2-08b42cb5e241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tm10007_ml' already exists and is not an empty directory.\n",
            "The number of samples: 827\n",
            "The number of columns: 9001\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!git clone https://github.com/jveenland/tm10007_ml.git\n",
        "\n",
        "with zipfile.ZipFile('/content/tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/tm10007_ml/ecg')\n",
        "\n",
        "data = pd.read_csv('/content/tm10007_ml/ecg/ecg_data.csv', index_col=0)\n",
        "\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nested cross-validation loop"
      ],
      "metadata": {
        "id": "1BwFjEOGWxm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SET UP ---\n",
        "# Split data into label and data\n",
        "label = data['label']\n",
        "data_nolabel = data.drop('label', axis=1)\n",
        "\n",
        "# K-fold outer cross-validation\n",
        "k_folds = 5\n",
        "cv_outer = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42) #random_state ensures same shuffling pattern\n",
        "\n",
        "# K-fold inner cross-validation\n",
        "n_folds = 5\n",
        "cv_inner = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42) #shuffle ensures no bias by ordered data\n",
        "\n",
        "# Classifiers\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(class_weight='balanced', random_state=42), # class weight balanced adjusts the weights of the classes because classes are unbalanced\n",
        "    \"SGDClassifier\": SGDClassifier(class_weight='balanced', random_state=42),\n",
        "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "    \"SVC\": SVC(class_weight='balanced', random_state=42),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(class_weight='balanced', random_state=42)}\n",
        "\n",
        "# Hyperparameters per classifier\n",
        "param_grids = {\n",
        "    \"LogisticRegression\": [\n",
        "        {\"C\": [0.01, 0.1, 1, 10], # Regularization strength\n",
        "         \"penalty\": ['l2'], # Regularization type\n",
        "         \"solver\": ['lbfgs']}, # Optimization algorithm\n",
        "        {\"C\": [0.01, 0.1, 1, 10],\n",
        "         \"penalty\": ['l2', 'l1'],\n",
        "         \"solver\": ['liblinear']}],\n",
        "    \"SGDClassifier\": {\n",
        "        \"loss\": ['hinge', 'log_loss', 'modified_huber'],  # Loss function\n",
        "        \"penalty\": ['l2', 'l1'],  # Regularization type\n",
        "        \"alpha\": [0.001, 0.01, 0.1]},  # Regularization amount\n",
        "    \"KNeighborsClassifier\": {\n",
        "        \"n_neighbors\": [2, 3, 5, 7, 9],  # Number of neighbors\n",
        "        \"weights\": ['uniform', 'distance']},  # Weighting scheme\n",
        "    \"DecisionTreeClassifier\": {\n",
        "        \"max_depth\": [3, 5, 7, 9, 11],  # Tree depth\n",
        "        \"min_samples_split\": [2, 5, 10, 15]},  # Minimum samples for split\n",
        "    \"SVC\": {\n",
        "        \"kernel\": ['linear', 'rbf', 'poly'],  # Kernel type\n",
        "        \"degree\": [2, 3, 5],  # Polynomial degree\n",
        "        \"C\": [0.1, 1, 10]},  # Regularization parameter\n",
        "    \"RandomForestClassifier\": {\n",
        "        \"n_estimators\": [1, 5, 10, 50],  # Number of trees\n",
        "        \"max_depth\": [3, 5, 7, 9, 11]}}  # Tree depth\n",
        "\n",
        "f1_threshold = 0.5\n",
        "f1_test = []\n",
        "precision_recall_list = []\n",
        "fold_num = 1\n",
        "\n",
        "# --- OUTER cross validation loop ---\n",
        "for train1_index, test_index in cv_outer.split(data_nolabel, label):\n",
        "    print(f\"Starting outer fold {fold_num}\")\n",
        "    fold_num += 1\n",
        "\n",
        "    # Split data into first train and test sets\n",
        "    X_train1, X_test = data_nolabel.iloc[train1_index], data_nolabel.iloc[test_index]\n",
        "    y_train1, y_test = label.iloc[train1_index], label.iloc[test_index]\n",
        "\n",
        "    ### Pre-processing\n",
        "    ## data checks\n",
        "    # Check which label is normal and abnormal\n",
        "    if sum(data['label']) > len(data) / 2: # Biggest class is 'normal'\n",
        "        normal_label = 0\n",
        "        abnormal_label = 1\n",
        "    else:\n",
        "        # Biggest class is 'abnormal'\n",
        "        normal_label = 1\n",
        "        abnormal_label = 0\n",
        "\n",
        "    # Check for normal distribution of features\n",
        "    p_values = X_train1.apply(lambda col: normaltest(col)[1]) # test normality of each feature and get p-value\n",
        "    non_normal_features = (p_values < 0.05).sum() # count number of features with p-value < 0.05 (not normally distributed)\n",
        "\n",
        "    ## Missing data handling\n",
        "    # Change None into median of training data\n",
        "    data_train_clean = X_train1.copy()\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    data_train_clean[:] = imputer.fit_transform(data_train_clean)\n",
        "\n",
        "    ## Scaling\n",
        "    # Find outliers in data\n",
        "    def count_outliers(df):\n",
        "      '''function to detect outliers in data'''\n",
        "      Q1 = df.quantile(0.25)\n",
        "      Q3 = df.quantile(0.75)\n",
        "      IQR = Q3 - Q1 # Spread of the middle 50% of data\n",
        "      lower_bound = Q1 - 1.5 * IQR\n",
        "      upper_bound = Q3 + 1.5 * IQR\n",
        "      outliers = ((df < lower_bound) | (df > upper_bound)).sum()\n",
        "      return outliers\n",
        "\n",
        "    outlier_counts = count_outliers(data_train_clean)\n",
        "    mean_outliers = outlier_counts.mean()\n",
        "    features_with_many_outliers = (outlier_counts > 0.1 * len(data_train_clean.index)).sum()\n",
        "\n",
        "    # MinMaxScaler chosen\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data_train_clean)\n",
        "\n",
        "    ## Feature selection\n",
        "    # 1. Univariate statistical testing: ANOVO f-test\n",
        "    # Number of features where p < 0.05\n",
        "    f_scores, p_values = f_classif(data_scaled, y_train1)\n",
        "    k_best = np.sum(p_values < 0.05) # Only features with p_value < 0.05\n",
        "\n",
        "    selector = SelectKBest(f_classif, k=k_best)\n",
        "    data_selected = selector.fit_transform(data_scaled, y_train1)\n",
        "    print(f'Univariatiate statistical feature selection performed: {k_best} features selected.')\n",
        "\n",
        "    # 2. Dimensionality reduction with PCA\n",
        "    # Number of components where variance ≥99%\n",
        "    pca_full = PCA().fit(data_selected)\n",
        "    explained_var = pca_full.explained_variance_ratio_\n",
        "    cumulative_var = np.cumsum(explained_var)\n",
        "    pca_components = np.argmax(cumulative_var >= 0.99) + 1   # find number of components that explain at least 99% of the variance\n",
        "\n",
        "    pca = PCA(n_components=pca_components) # Reduce to features so that variance > 0.99\n",
        "    data_final_selected = pca.fit_transform(data_selected)\n",
        "    print(f'PCA feature selection performed: {pca_components} features left.')\n",
        "\n",
        "    # initialize for storage\n",
        "    clf_params = {}\n",
        "    auc_scores = {}\n",
        "    f1_scores = {}\n",
        "    ensemble_classifiers = []\n",
        "    ensemble_fold_indices = []\n",
        "\n",
        "    inner_fold_num = 1\n",
        "\n",
        "    # --- INNER cross validation loop ---\n",
        "    for train_index, val_index in cv_inner.split(data_final_selected, y_train1):\n",
        "        print(f\"Starting inner fold {inner_fold_num}\")\n",
        "\n",
        "        # Split data into train and validation sets\n",
        "        X_train, X_val = data_final_selected[train_index], data_final_selected[val_index]\n",
        "        y_train, y_val = y_train1.iloc[train_index], y_train1.iloc[val_index]\n",
        "\n",
        "        # Store classifiers for ensembling\n",
        "        fold_classifiers = []\n",
        "\n",
        "        # Create learning curve plots\n",
        "        i=0\n",
        "        fig, axes = plt.subplots(2, len(classifiers), figsize=(25, 20))\n",
        "\n",
        "        # --- classifier loop ---\n",
        "        for clf_name, clf in classifiers.items():\n",
        "          # initialize list to store results\n",
        "          clf_params.setdefault(clf_name, [])\n",
        "          auc_scores.setdefault(clf_name, [])\n",
        "          auc_scores.setdefault('VotingEnsembleHard', [])\n",
        "          f1_scores.setdefault(clf_name, [])\n",
        "          f1_scores.setdefault('VotingEnsembleHard', [])\n",
        "\n",
        "          ## Hyperparameter optimization\n",
        "          # find best hyperparams for current classifier\n",
        "          grid_search = GridSearchCV(clf, param_grids[clf_name], cv=cv_inner, n_jobs=-1, scoring='f1')\n",
        "          grid_search.fit(X_train, y_train)\n",
        "          clf = grid_search.best_estimator_    # get best estimator\n",
        "          clf_params[clf_name].append(clf)     # store best estimator\n",
        "          print(f\"Best parameters for {clf_name}: {grid_search.best_params_}\")\n",
        "\n",
        "          ### Visualisation\n",
        "          ## Calculate AUC-score\n",
        "          y_pred = clf.predict(X_val)\n",
        "          if hasattr(clf, \"predict_proba\"):\n",
        "              y_score = clf.predict_proba(X_val)[:, 1]\n",
        "          elif hasattr(clf, \"decision_function\"):\n",
        "              y_score = clf.decision_function(X_val)\n",
        "          else:\n",
        "              y_score = y_pred  # fallback if neither method is available\n",
        "\n",
        "          auc = roc_auc_score(y_val, y_score)\n",
        "          auc_scores[clf_name].append(auc)  # Store AUC for this classifier\n",
        "\n",
        "          ## Calculate F1-score for this classifier\n",
        "          f1 = f1_score(y_val, y_pred)\n",
        "          f1_scores[clf_name].append(f1)  # Store F1-score for this classifier\n",
        "\n",
        "          # Calculate ROC\n",
        "          fpr, tpr, thresholds = roc_curve(y_val, y_score)\n",
        "\n",
        "          # Plot ROC curve for each classifier\n",
        "          axes[0,i].plot(fpr, tpr, label=f'{clf_name} (AUC = {auc:.2f})')\n",
        "          axes[0,i].plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "          axes[0,i].set_xlabel('False Positive Rate')\n",
        "          axes[0,i].set_ylabel('True Positive Rate')\n",
        "          axes[0,i].set_title(f'ROC Curve - {clf_name}')\n",
        "          axes[0,i].legend()\n",
        "\n",
        "          ## Learning curves\n",
        "          train_sizes, train_scores, val_scores = \\\n",
        "            learning_curve(clf, X_train, y_train,\n",
        "                            cv=cv_inner,n_jobs=4, train_sizes=np.linspace(0.1, 1.0, 5))\n",
        "\n",
        "          # calculate mean and std of training and validation scores\n",
        "          train_scores_mean = np.mean(train_scores, axis=1)\n",
        "          train_scores_std = np.std(train_scores, axis=1)\n",
        "          val_scores_mean = np.mean(val_scores, axis=1)\n",
        "          val_scores_std = np.std(val_scores, axis=1)\n",
        "\n",
        "          # plot learning curve\n",
        "          axes[1,i].set_title(f'Learning Curve - {clf_name}')\n",
        "          axes[1,i].set_ylim(0.3, 1.01) # Adjust ylim as needed\n",
        "          axes[1,i].set_xlabel(\"Training examples\")\n",
        "          axes[1,i].set_ylabel(\"Score\")\n",
        "          axes[1,i].grid()\n",
        "          axes[1,i].fill_between(train_sizes,train_scores_mean - train_scores_std,\n",
        "                              train_scores_mean + train_scores_std,alpha=0.1,color=\"r\")\n",
        "          axes[1,i].fill_between(train_sizes,val_scores_mean - val_scores_std,val_scores_mean + val_scores_std,alpha=0.1,color=\"g\")\n",
        "          axes[1,i].plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
        "          axes[1,i].plot(train_sizes, val_scores_mean, \"o-\", color=\"g\",\n",
        "                      label=\"Cross-validation score\")\n",
        "          axes[1,i].legend(loc=\"best\")\n",
        "\n",
        "          i += 1\n",
        "\n",
        "          ## Selection for ensembling based on f1-score value\n",
        "          if f1 > f1_threshold: # Store high scoring classifiers\n",
        "            fold_classifiers.append((clf_name, clf))\n",
        "\n",
        "      # Out of classifier loop, still in cross-validation loop\n",
        "      ## Ensembling\n",
        "        if len(fold_classifiers) > 1:  # Cannot ensemble 1 classifier\n",
        "            voting_ensemble = VotingClassifier(estimators=fold_classifiers, voting='hard')\n",
        "            voting_ensemble.fit(X_train, y_train)\n",
        "            y_pred = voting_ensemble.predict(X_val)\n",
        "            f1 = f1_score(y_val, y_pred)\n",
        "            f1_scores['VotingEnsembleHard'].append(f1)\n",
        "            ensemble_classifiers.append(voting_ensemble)\n",
        "        else:\n",
        "            clf_names = [name for name, _ in fold_classifiers]\n",
        "            print(f\"Only {len(fold_classifiers)} classifier(s) above F1 threshold in inner fold {inner_fold_num}: {clf_names}. Skipping ensembling.\")\n",
        "\n",
        "        ensemble_fold_indices.append(inner_fold_num)\n",
        "        inner_fold_num += 1\n",
        "\n",
        "    # Out of cross-validation loop\n",
        "    ## Select best ensembling model\n",
        "    if f1_scores['VotingEnsembleHard']:\n",
        "        best_f1 = max(f1_scores['VotingEnsembleHard'])\n",
        "        best_idx = f1_scores['VotingEnsembleHard'].index(best_f1)\n",
        "        best_ensemble = ensemble_classifiers[best_idx]\n",
        "        best_inner_fold = ensemble_fold_indices[best_idx]\n",
        "        print(f'Best ensemble model created in inner fold {best_inner_fold} with F1 score {best_f1:.4f}')\n",
        "    else:\n",
        "        best_ensemble = None\n",
        "        best_f1, best_idx, best_clf_name = max(\n",
        "            [(value, i, key) for key, values in f1_scores.items() for i, value in enumerate(values)],\n",
        "            key=lambda item: item[0])\n",
        "        best_clf = clf_params[best_clf_name][best_idx]\n",
        "        print(f'Best individual classifier: {best_clf_name} from inner fold {best_idx + 1} with F1 score {best_f1:.4f}')\n",
        "\n",
        "    ## Evaluate model on test data\n",
        "    # Change None into median of train data\n",
        "    data_test_clean = X_test.copy()\n",
        "    data_test_clean[:] = imputer.transform(data_test_clean)\n",
        "    # Scaling testdata\n",
        "    X_test_scaled = scaler.transform(data_test_clean)\n",
        "    # Feature selection\n",
        "    X_test_selected = selector.transform(X_test_scaled) # 1. univariate\n",
        "    X_test_final_selected = pca.transform(X_test_selected) # 2. pca\n",
        "\n",
        "    # Ensembling\n",
        "    if best_ensemble:  # if ensemble is created, use for prediction\n",
        "        y_pred_test = best_ensemble.predict(X_test_final_selected)\n",
        "        f1_test_fold = f1_score(y_test, y_pred_test)\n",
        "        f1_test.append(f1_test_fold)\n",
        "        print(f\"Final ensemble model used — F1-score on test data: {f1_test_fold:.4f}\")\n",
        "\n",
        "        print(\"Ensemble includes the following classifiers:\")\n",
        "        for name, estimator in best_ensemble.estimators:\n",
        "            print(f\" - {name}: {estimator}\")\n",
        "    else:  # otherwise use best individual classifier for prediction\n",
        "        y_pred_test = best_clf.predict(X_test_final_selected)\n",
        "        f1_test_fold = f1_score(y_test, y_pred_test)\n",
        "        f1_test.append(f1_test_fold)\n",
        "        print(f\"Final individual model ({best_clf_name}) used — F1-score on test data: {f1_test_fold:.4f}\")\n",
        "\n",
        "    ## Final evaluation\n",
        "    # Calculate precision, recall, and thresholds\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_test)\n",
        "    # Calculate Average Precision (AP)\n",
        "    average_precision = average_precision_score(y_test, y_pred_test)\n",
        "    # Add to list\n",
        "    precision_recall_data = (precision, recall, average_precision)\n",
        "    precision_recall_list.append(precision_recall_data)\n"
      ],
      "metadata": {
        "id": "V6pFCX3R9Mol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "0dc29798-eaf3-4df2-cf8b-dac634660062"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting outer fold 1\n",
            "Univariatiate statistical feature selection performed: 845 features selected.\n",
            "PCA feature selection performed: 258 features left.\n",
            "Starting inner fold 1\n",
            "Best parameters for LogisticRegression: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c77fd1fcba71>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m           \u001b[0;31m## Calculate F1-score for this classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m           \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0mf1_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Store F1-score for this classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x2000 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Out of outer cross-validation loop\n",
        "Visualisation"
      ],
      "metadata": {
        "id": "0C4_0LqrzHEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize f-scores for univariate feature selection\n",
        "sorted_scores = np.sort(f_scores)[::-1]  # Sort on descending\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(sorted_scores[:2000])\n",
        "plt.axvline(x=k_best, color='r', linestyle='--', label=f'{k_best} features selected')\n",
        "plt.title('Sorted ANOVA F-scores of features')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('F-score')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot variance for PCA\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(cumulative_var, marker='o', label='Cumulative variance')\n",
        "plt.axhline(y=0.99, color='r', linestyle='--', label='99%') # earlier defined 99% variance threshold for PCA\n",
        "plt.axvline(x=pca_components, color='g', linestyle='--', label=f'{pca_components} components')\n",
        "plt.title('Cumulative variance per PCA-component')\n",
        "plt.xlabel('Number of PCA-components')\n",
        "plt.ylabel('Cumulative variance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Visualize new features with t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42) # Reduce to 2 dimensions for plotting\n",
        "data_tsne = tsne.fit_transform(data_final_selected)\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(data_tsne[y_train1 == 0, 0], data_tsne[y_train1 == 0, 1], label='Label 0', marker='o')  # Plot points for label 0\n",
        "plt.scatter(data_tsne[y_train1 == 1, 0], data_tsne[y_train1 == 1, 1], label='Label 1', marker='x')  # Plot points for label 1\n",
        "plt.legend()  # Add a legend to identify the labels\n",
        "plt.title('t-SNE Visualization of Selected Features')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SyMaRFaszPgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance estimate"
      ],
      "metadata": {
        "id": "w_JSeS85zQAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_test_mean = np.mean(f1_test)\n",
        "print(f\"mean F1-score on testdata: {f1_test_mean}\")\n",
        "\n",
        "# confusion matrix\n",
        "metrics.confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=metrics.confusion_matrix(y_test, y_pred_test),\n",
        "                              display_labels=np.unique(y_test)) # Changed to unique labels in filtered_label_test\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# # Plot Precision-Recall curve\n",
        "\n",
        "all_precisions = []\n",
        "all_recalls = []\n",
        "all_average_precisions = []\n",
        "fig, ax = plt.subplots()\n",
        "for i, (precision, recall, average_precision) in enumerate(precision_recall_list):\n",
        "    all_precisions.append(precision)\n",
        "    all_recalls.append(recall)\n",
        "    all_average_precisions.append(average_precision)\n",
        "    # Plot Precision-Recall curve\n",
        "    display = PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=average_precision)\n",
        "    display.plot(ax=ax, name=f\"Fold {i+1}\", linestyle='--')  # Plot on the same axes with a label for each fold\n",
        "\n",
        "display = PrecisionRecallDisplay(precision=np.mean(all_precisions, axis=0), recall=np.mean(all_recalls, axis=0), average_precision=np.mean(all_average_precisions))\n",
        "display.plot(ax=ax, name=f\"All Folds\", linestyle='-')  # Plot on the same axes with a label for each fold\n",
        "plt.title('Precision-Recall curve for All Folds')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oxm-PzFnzeav"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}