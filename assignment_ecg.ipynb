{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template -- ECG data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_VsRlKukSmc"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "lK44S6bKvDvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV\n",
        "\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "hWbJd3An9_NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "!git clone https://github.com/jveenland/tm10007_ml.git\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "with zipfile.ZipFile('/content/tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/tm10007_ml/ecg')\n",
        "\n",
        "data = pd.read_csv('/content/tm10007_ml/ecg/ecg_data.csv', index_col=0)\n",
        "\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing**"
      ],
      "metadata": {
        "id": "zU0UNSLR9c0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate labels"
      ],
      "metadata": {
        "id": "fRGWMzvjmWXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data has a 'label' column indicating the class\n",
        "label = data['label']\n",
        "\n",
        "# Separate data based on the label\n",
        "if sum(data['label']) > len(data) / 2:\n",
        "    normal_data = data[label == 0]\n",
        "    abnormal_data = data[label == 1]\n",
        "else:\n",
        "    normal_data = data[label == 1]\n",
        "    abnormal_data = data[label == 0]\n",
        "\n",
        "# Create data without the labels\n",
        "data_no_label = data.drop('label', axis=1)  # All features"
      ],
      "metadata": {
        "id": "AjjHQexaEFDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing data handling"
      ],
      "metadata": {
        "id": "5s9S-RYWmWIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Check for missing data\n",
        "# Check for any None values in data\n",
        "has_missing = data.isnull().values.any()\n",
        "print(f\"Missing values present? {has_missing}\")\n",
        "\n",
        "# Check for any zeros in data\n",
        "has_zeros = (data_no_label == 0).values.any()\n",
        "print(f\"Zero values present? {has_zeros}\")\n",
        "\n",
        "# Calculate total number of zeros\n",
        "total_zeros = (data_no_label == 0).sum().sum()\n",
        "print(f\"Total zeros in DataFrame: {total_zeros}\")\n",
        "\n",
        "##### Overview of where zeros are to decide missing data handling strategy\n",
        "# Count how many rows have at least one zero\n",
        "rows_with_zero = (data_no_label == 0).any(axis=1).sum()\n",
        "print(f\"Number of rows with at least one zero: {rows_with_zero}\")\n",
        "\n",
        "# Count how many columns have at least one zero\n",
        "columns_with_zero = (data_no_label == 0).any(axis=0).sum()\n",
        "print(f\"Number of columns with at least one zero: {columns_with_zero}\")\n",
        "\n",
        "# Create table with zero count for the rows\n",
        "zero_counts_per_row = (data_no_label == 0).sum(axis=1)\n",
        "zero_count_table = pd.DataFrame({'Row_Index': data_no_label.index, 'Zero_Count': zero_counts_per_row})\n",
        "zero_count_table.set_index('Row_Index', inplace=True)\n",
        "\n",
        "# Create table with zero count for the columns\n",
        "zero_counts_per_column = (data_no_label == 0).sum(axis=0)\n",
        "zero_count_table = pd.DataFrame({'Column_Name': zero_counts_per_column.index, 'Zero_Count': zero_counts_per_column.values})\n",
        "zero_count_table.set_index('Column_Name', inplace=True)\n",
        "\n",
        "##### Remove missing data\n",
        "# Remove rows with more than 10 zeros\n",
        "zero_counts_per_row = (data_no_label == 0).sum(axis=1)\n",
        "rows_to_keep = zero_counts_per_row[zero_counts_per_row <= 10].index\n",
        "filtered_data = data_no_label.loc[rows_to_keep]\n",
        "\n",
        "# Print removed rows with zeros\n",
        "data_with_zeros = data_no_label[(data_no_label == 0).any(axis=1)]\n",
        "zero_counts_per_row = (data_with_zeros == 0).sum(axis=1)\n",
        "print(zero_counts_per_row)\n",
        "\n",
        "# Check if all rows with zeros are removed\n",
        "rows_with_zero = (filtered_data == 0).any(axis=1).sum()\n",
        "print(f\"Number of rows with at least one zero (filtered data): {rows_with_zero}\")\n",
        "\n",
        "# Calculate total number of zeros to make sure all are removed from the whole dataframe\n",
        "total_zeros = (filtered_data == 0).sum().sum()\n",
        "print(f\"Total zeros in the DataFrame (excluding last column) after removing rows with zeros: {total_zeros}\")"
      ],
      "metadata": {
        "id": "G-phISsk9dJA",
        "outputId": "ae818e10-5da0-49a7-98ba-ae519c3ba73f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values present? False\n",
            "Zero values present? True\n",
            "Total zeros in DataFrame: 10500\n",
            "Number of rows with at least one zero: 14\n",
            "Number of columns with at least one zero: 4500\n",
            "177    750\n",
            "251    750\n",
            "269    750\n",
            "321    750\n",
            "323    750\n",
            "385    750\n",
            "434    750\n",
            "446    750\n",
            "537    750\n",
            "542    750\n",
            "575    750\n",
            "601    750\n",
            "784    750\n",
            "790    750\n",
            "dtype: int64\n",
            "Number of rows with at least one zero (filtered data): 0\n",
            "Total zeros in the DataFrame (excluding last column) after removing rows with zeros: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test data"
      ],
      "metadata": {
        "id": "RtmLVi359L4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing set (for final evaluation als dit nodig is)\n",
        "data_train, data_test, label_train, label_test = train_test_split(data_no_label, label, test_size=0.2, random_state=42, stratify=label)\n",
        "\n",
        "# Define K-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "V6pFCX3R9Mol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling: normalisation or standardisation"
      ],
      "metadata": {
        "id": "mL1Yg6Mz9n14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "data_standardized = scaler.fit_transform(data_no_label)\n",
        "data_standardized = pd.DataFrame(data_standardized, columns=data_no_label.columns, index=data_no_label.index)  # Convert back to DataFrame\n",
        "\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "data_normalized = scaler.fit_transform(data_no_label)\n",
        "data_normalized = pd.DataFrame(data_normalized, columns=data_no_label.columns, index=data_no_label.index)  # Convert back to DataFrame\n",
        "\n",
        "# Decide to use standardization or normalization, based on performance metrics (accuracy, precision, recall)\n",
        "# For now start with standardization --> default choice"
      ],
      "metadata": {
        "id": "Y5gQVA3x9umI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature selection and extraction**"
      ],
      "metadata": {
        "id": "c3NGZOr1usBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Preliminary filtering using univariate statistical testing: ANOVA f-test\n",
        "selector = SelectKBest(f_classif, k=1000) # Select top 1000 features\n",
        "data_selected = selector.fit_transform(data_train, label_train) # Fit to the training data\n",
        "\n",
        "# Get the names of the top 1000 features\n",
        "selected_feature_indices = selector.get_support(indices=True)  # Get indices of selected features\n",
        "selected_feature_names = data_train.columns[selector.get_support()] # Data is pandas dataframe\n",
        "\n",
        "# Dataframe with selected features for training data\n",
        "data_selected = pd.DataFrame(data_selected, columns=selected_feature_names, index=data_train.index)\n",
        "\n",
        "print('Univariatiate statistical feature selection performed: 1000 features left.')\n",
        "\n",
        "# 2. Dimensionality reduction using PCA\n",
        "pca = PCA(n_components=100)  # Reduce to 100 features\n",
        "data_pca_selected = pca.fit_transform(data_selected) # Fit to the training data\n",
        "\n",
        "# Dataframe with PCA-transformed features for training data\n",
        "data_pca_selected = pd.DataFrame(data_pca_selected, index=data_selected.index)\n",
        "\n",
        "print('PCA feature selection performed: 100 features left.')\n",
        "\n",
        "# 3. Visualize new features with t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42) # Reduce to 2 dimensions for plotting\n",
        "data_tsne = tsne.fit_transform(data_pca_selected)\n",
        "\n",
        "# Create a scatter plot\n",
        "#plt.figure(figsize=(8, 6))\n",
        "#plt.scatter(data_tsne[label_train == 0, 0], data_tsne[label_train == 0, 1], label='Label 0', marker='o')  # Plot points for label 0\n",
        "#plt.scatter(data_tsne[label_train == 1, 0], data_tsne[label_train == 1, 1], label='Label 1', marker='x')  # Plot points for label 1\n",
        "#plt.legend()  # Add a legend to identify the labels\n",
        "#plt.title('t-SNE Visualization of Selected Features')\n",
        "#plt.xlabel('t-SNE Dimension 1')\n",
        "#plt.ylabel('t-SNE Dimension 2')\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "6H6QYLK0up7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}